# ğŸ“„ Clinical PDF Feature Extraction Pipeline (LLM-Powered)

An end-to-end system to extract **structured clinical features** from biomedical PDFs using **LLMs**, with a **live interactive UI** for demos.

This project covers the full pipeline:
- Web scraping â†’ PDF discovery
- Robust PDF text & table extraction
- Chunked LLM inference with caching
- Clean CSV outputs
- Streamlit UI for real-time interaction (â‰¤10 PDFs)

---

## ğŸš€ Demo (UI Walkthrough)

### 1ï¸âƒ£ Upload Clinical PDFs
Users can upload **up to 10 PDFs** at once using the web UI.

![Upload PDFs](assets/demo_upload.png)

---

### 2ï¸âƒ£ Live Extraction with Progress Tracking
Each PDF is processed independently:
- Text + tables extracted
- Content chunked
- LLM invoked with structured JSON prompts
- Progress shown per file

![Processing Progress](assets/demo_processing.png)

---

### 3ï¸âƒ£ Structured Clinical Features (Final Output)
For each PDF, the system extracts fields such as:
- Typical age of onset  
- Gender predominance  
- Presenting symptoms  
- Key investigations  
- Treatability & manageability  

The results are displayed as a table and can be downloaded as CSV.

![Result Table](assets/demo_result.png)



## ğŸ§  Extracted Clinical Fields

Each PDF yields a structured row with the following schema:

- `typical_age_of_onset`
- `gender_predominance`
- `life_expectancy`
- `presenting_symptoms_signs`
- `key_investigations_for_confirmation`
- `clinical_presentation`
- `manageability`
- `treatability`
- `onset_age`
- `file_name`
- `error` (empty if successful)

---

## ğŸ—ï¸ Architecture Overview

```text
Web Scraping (Node.js)
        â†“
Direct PDF Resolution
        â†“
PDF Text + Table Extraction
(pdfplumber, camelot, tabula)
        â†“
Chunked LLM Inference (Ollama)
        â†“
JSON Validation + Merging
        â†“
CSV Output + Streamlit UI
```

Key design choices:
- Chunk-level caching to avoid re-querying the LLM
- Multiple table extraction backends for robustness
- Strict JSON validation for reliable downstream use
- Ephemeral file handling for privacy-safe demos

---

## ğŸ“ Repository Structure

```text
clinical-pdf-feature-extraction/
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ extract_clinical_features.py
â”‚   â”œâ”€â”€ ui_app.py
â”‚
â”œâ”€â”€ node/
â”‚   â”œâ”€â”€ web_scrapper.js
â”‚   â”œâ”€â”€ to_csv.js
â”‚
â”œâ”€â”€ pdfs/            # Temporary runtime uploads (empty in repo)
â”œâ”€â”€ results/         # Debug traces & extracted tables
â”œâ”€â”€ cache_ollama/    # LLM response cache
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone & create virtual environment
```bash
git clone https://github.com/premdev1234/clinical-pdf-feature-extraction.git
cd clinical-pdf-feature-extraction
python -m venv .venv
```

### 2ï¸âƒ£ Activate venv

**Windows**
```powershell
.\.venv\Scripts\Activate
```

**Linux / macOS**
```bash
source .venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run the UI (Recommended)

```powershell
.\.venv\Scripts\python -m streamlit run python/ui_app.py
```

Open in browser:
```
http://localhost:8501
```

---

## ğŸ” File Handling & Privacy

- Uploaded PDFs are stored in a temporary session directory
- Files are processed and removed automatically
- No PDFs or private data are committed to GitHub
- Only structured outputs are downloadable

---

## ğŸ§© System Dependencies (Important)

Some features require external tools:

- Ollama (LLM inference)
- Java 8+ (for tabula-py)
- Tesseract OCR (for scanned PDFs)
- Ghostscript (recommended for Camelot)

---

## ğŸ¯ Use Cases

- Clinical literature mining  
- Rare disease phenotype summarization  
- Pre-processing for genotypeâ€“phenotype mapping  
- Structured inputs for downstream ML / research pipelines  

---

## ğŸ“œ License

MIT License

---

